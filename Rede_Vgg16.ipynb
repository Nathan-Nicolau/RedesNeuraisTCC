{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5p35QAZRVITblUTVHMLgD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nathan-Nicolau/RedesNeuraisTCC/blob/main/Rede_Vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Substitua 'caminho_para_sua_pasta_principal_com_24_subpastas' pelo caminho real no seu Google Drive\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/CromossomosAjustados_100_x_100/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66haiYZv-471",
        "outputId": "7b762d98-5582-48ee-f2ca-a6ad066e807d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOEaivHX-vgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977f702c-01a1-467a-f666-a7f44c4344e3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12013 images belonging to 24 classes.\n",
            "Found 12013 images belonging to 24 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Substitua 'caminho_para_sua_pasta_principal_com_24_subpastas' pelo caminho real\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/Dataset/CromossomosAjustados_100_x_100/'\n",
        "\n",
        "# Use a função ImageDataGenerator para aplicar aumentação de dados durante o treinamento\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Divida as pastas em treinamento e teste\n",
        "train_dir = os.path.join(base_dir)\n",
        "test_dir = os.path.join(base_dir)\n",
        "\n",
        "# Carregue dados de treinamento e teste usando o ImageDataGenerator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 100),\n",
        "    batch_size=256,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 100),\n",
        "    batch_size=256,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Crie o modelo VGG16\n",
        "base_model = VGG16(\n",
        "    weights='imagenet', include_top=False, input_shape=(150, 100, 3))\n",
        "\n",
        "# Congele as camadas convolucionais do modelo VGG16 pré-treinado\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adicione camadas personalizadas no topo\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(24, activation='softmax'))  # 24 classes de saída\n",
        "\n",
        "# Compile o modelo\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Registre o tempo de início\n",
        "start_time = time.time()\n",
        "\n",
        "# Treine o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // test_generator.batch_size\n",
        ")\n",
        "\n",
        "# Registre o tempo de término\n",
        "end_time = time.time()\n",
        "\n",
        "# Calcule o tempo total de execução\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f'Tempo total de execução: {total_time:.2f} segundos')\n",
        "\n",
        "# Avalie o modelo\n",
        "test_loss, test_acc = model.evaluate(\n",
        "    test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Visualize o desempenho do treinamento\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Gráfico de Barras para Métricas Numéricas\n",
        "y_true = test_generator.classes\n",
        "y_scores = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size).argmax(axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_scores)\n",
        "precision = precision_score(y_true, y_scores, average='weighted')\n",
        "recall = recall_score(y_true, y_scores, average='weighted')\n",
        "f1 = f1_score(y_true, y_scores, average='weighted')\n",
        "\n",
        "metrics = ['Acurácia', 'Precisão', 'Recall', 'Pontuação F1']\n",
        "values = [accuracy, precision, recall, f1]\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Métricas de Desempenho')\n",
        "\n",
        "# Matriz de Confusão\n",
        "plt.subplot(1, 3, 2)\n",
        "confusion_mat = confusion_matrix(y_true, y_scores)\n",
        "sns.heatmap(confusion_mat, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "\n",
        "# Gráfico ROC\n",
        "plt.subplot(1, 3, 3)\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Salvar o modelo treinado\n",
        "model.save('RedeVGG16_treinada.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Uso do modelo treinado para reconhecer novas imagens\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Monte o Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Carregue o modelo treinado\n",
        "loaded_model = load_model('/content/drive/MyDrive/seu_caminho/RedeVGG16_treinada.h5')\n",
        "\n",
        "# Substitua 'caminho_para_pastas_principais_com_24_subpastas' pelo caminho real no Google Drive\n",
        "base_folder = '/content/drive/MyDrive/seu_caminho/NovasImagens/'\n",
        "\n",
        "# Loop através das 24 pastas\n",
        "for folder_name in os.listdir(base_folder):\n",
        "    folder_path = os.path.join(base_folder, folder_name)\n",
        "\n",
        "    # Loop através das imagens em cada pasta\n",
        "    for image_name in os.listdir(folder_path):\n",
        "        image_path = os.path.join(folder_path, image_name)\n",
        "\n",
        "        # Carregue e pré-processe a imagem\n",
        "        new_image = image.load_img(image_path, target_size=(150, 100))\n",
        "        new_image = image.img_to_array(new_image)\n",
        "        new_image = np.expand_dims(new_image, axis=0)\n",
        "        new_image = new_image / 255.0  # Normalização\n",
        "\n",
        "        # Faça a previsão\n",
        "        predictions = loaded_model.predict(new_image)\n",
        "\n",
        "        # Exiba as previsões ou faça o que for necessário com elas\n",
        "        print(f'Pasta: {folder_name}, Imagem: {image_name}, Previsões: {predictions}')\n"
      ],
      "metadata": {
        "id": "JV94jhzAFQ30"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}